{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install numpy==1.16.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/deeplearn')\nsys.path.append('/kaggle/input/bertdp')\nsys.path.append('/kaggle/input')\nsys.path.append('/kaggle/input/tensorr/tensorflow/_api/v1')\nimport deeppavlov\nimport tensorflow ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /kaggle/input/gggggggg/__init__.py /kaggle/input/tensorr/tensorflow/_api/v1/__init__.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from deeppavlov import build_model, configs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model('/kaggle/input/config/config.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nimport numpy as np \nimport pandas as pd\nimport re\nimport random\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/tensorflow2-question-answering/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm_notebook as tqdm\nfrom Levenshtein import ratio as levenshtein_distance\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.feature_extraction import text\n\nfrom scipy import spatial\nfrom deeppavlov import build_model, configs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = ['is', 'are', 'do', 'does', 'did', 'was', 'were', 'will', 'can', 'the', 'a', 'of', 'in', 'and', 'on', \\\n         'what', 'where', 'when', 'which' + '<P>', '</P>', '<Table>', '</Table>', '<Tr>', '</Tr>', '<Ul>', '<Ol>', '<Dl>', '</Ul>', '</Ol>', \\\n             '</Dl>', '<Li>', '<Dd>', '<Dt>', '</Li>', '</Dd>', '</Dt>']\n\nquestion_words = ['is', 'are', 'do', 'does', 'did', 'was', 'were', 'will', 'can']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(x):\n    x = x.lower()\n    for r in tags:\n        x = x.replace(r, '')\n    x = re.sub(' +', ' ', x)\n    return x\n\ndef find(start, text, string):\n    fnd = string.split(\" \")\n    res = text.split(\" \")\n    for i in fnd:\n        for j in range(len(res)):\n            if i == res[j] and (j + len(fnd) - 1) < len(res) and fnd[-1] == res[j + len(fnd) - 1]:\n                return start + j, start + j + len(fnd)\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(json_data):\n    candidates = json_data['long_answer_candidates']\n    candidates = [c for c in candidates if c['top_level'] == True]\n    doc_tokenized = json_data['document_text'].split(' ')\n    question = json_data['question_text'].split(' ') \n\n    tfidf = TfidfVectorizer(ngram_range=(1,3), stop_words=text.ENGLISH_STOP_WORDS.union([\"book\"]))\n    tfidf.fit([json_data['document_text']])\n    q_tfidf = tfidf.transform([json_data['question_text']]).todense()\n\n    scores = []\n    count = 1\n    for i, c in enumerate(candidates):\n        s, e = c['start_token'], c['end_token']\n        t = ' '.join(doc_tokenized[s:e])\n        t_tfidf = tfidf.transform([t]).todense()\n        score = 1 - spatial.distance.cosine(q_tfidf, t_tfidf)\n        \n        if doc_tokenized[s] == '<P>':\n            score += 0.25**count\n            count += 1\n        scores.append(score)\n        \n    ans = (np.array(candidates)[np.argsort(scores)])[-1:].tolist()\n    \n    if np.max(scores) < 0.15:\n        long = ['-1:-1']\n        ans = [{'start_token': 0, 'end_token': 0}]\n    else:\n        long = [str(a['start_token']) + ':' + str(a['end_token']) for a in ans]\n        answer_short = model([\" \".join(doc_tokenized[ans[0][\"start_token\"]:ans[0][\"end_token\"]])], [json_data['question_text']])[0][0]\n        tmp = find(ans[0][\"start_token\"],\" \".join(doc_tokenized[ans[0][\"start_token\"]:ans[0][\"end_token\"]]) ,answer_short)\n        if tmp:\n            short = str(tmp[0]) + ':' + str(tmp[1])\n        else:\n            if question[0] in question_words:\n                short = 'YES'\n            else:\n                short = ''\n            \n    return long, short","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = []\npreds = []\n\nwith open('/kaggle/input/tensorflow2-question-answering/simplified-nq-test.jsonl', 'r') as json_file:\n    for line in tqdm(json_file): \n        json_data = json.loads(line)\n        l_ans, s_ans = predict(json_data)\n        ids += [str(json_data['example_id']) + '_long']*len(l_ans)\n        ids.append(str(json_data['example_id']) + '_short')\n        preds += l_ans\n        preds.append(s_ans) \n        \ndf = pd.DataFrame()\ndf['example_id'] = ids\ndf['PredictionString'] = preds\nsub = df[['example_id', 'PredictionString']].groupby('example_id').agg(lambda x: ' '.join(x) if len(x) > 1 else x).reset_index()\nsub.to_csv('submission.csv', index=False)\n\nsub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}